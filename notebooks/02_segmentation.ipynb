{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davi/projects/TI0160-visao-computacional/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "from medpy.metric.binary import hd, asd \n",
    "\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "PATCH_SIZE = (256, 256)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 30\n",
    "N_WORKERS = 10\n",
    "MODELS_PATH = \"models/segmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Covid19Dataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths):\n",
    "        \"\"\"\n",
    "        image_paths: Lista de caminhos das imagens.\n",
    "        mask_paths: Lista de caminhos das máscaras correspondentes.\n",
    "        \"\"\"\n",
    "        self.transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize(PATCH_SIZE),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        # Carrega a imagem e a máscara\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "root_dir = \"data/raw\"\n",
    "\n",
    "all_image_paths = []\n",
    "all_mask_paths = []\n",
    "\n",
    "for class_name in os.listdir(root_dir):\n",
    "    class_dir = os.path.join(root_dir, class_name)\n",
    "\n",
    "    if os.path.isdir(class_dir):\n",
    "        image_dir = os.path.join(class_dir, \"images\")\n",
    "        mask_dir = os.path.join(class_dir, \"masks\")\n",
    "\n",
    "        img_names = sorted(os.listdir(image_dir))\n",
    "\n",
    "        for img_name in img_names[:250]:\n",
    "            img_path = os.path.join(image_dir, img_name)\n",
    "            mask_path = os.path.join(mask_dir, img_name)\n",
    "            all_image_paths.append(img_path)\n",
    "            all_mask_paths.append(mask_path)\n",
    "\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(\n",
    "    all_image_paths, all_mask_paths, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Covid19Dataset(train_images, train_masks)\n",
    "test_dataset = Covid19Dataset(test_images, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, loss_fn, optimizer, n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, masks in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = loss_fn(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(loader)\n",
    "        print(f'Epoch {epoch+1}/{n_epochs} / Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target):\n",
    "    smooth = 1e-6  # Para evitar divisão por zero\n",
    "    intersection = (pred * target).sum()\n",
    "    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "\n",
    "def jaccard_index(pred, target):\n",
    "    pred = pred.flatten()\n",
    "    target = target.flatten()\n",
    "    return jaccard_score(target, pred)\n",
    "\n",
    "def hausdorff_distance(pred, target):\n",
    "    pred_np = pred.cpu().numpy().astype(bool)\n",
    "    target_np = target.cpu().numpy().astype(bool)\n",
    "\n",
    "    return hd(pred_np, target_np)\n",
    "\n",
    "def average_surface_distance(pred, target):\n",
    "    pred_np = pred.cpu().numpy().astype(bool)\n",
    "    target_np = target.cpu().numpy().astype(bool)\n",
    "    return asd(pred_np, target_np)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "    jaccard_scores = []\n",
    "    hausdorff_distances = []\n",
    "    avg_surface_distances = []\n",
    "    times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "\n",
    "            start_time = time.time()\n",
    "            outputs = model(images)\n",
    "            end_time = time.time()\n",
    "\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                pred = preds[i].cpu()\n",
    "                mask = masks[i].cpu()\n",
    "\n",
    "                dice = dice_coefficient(pred, mask)\n",
    "                dice_scores.append(dice)\n",
    "\n",
    "                jaccard = jaccard_index(pred, mask)\n",
    "                jaccard_scores.append(jaccard)\n",
    "\n",
    "                hausdorff = hausdorff_distance(pred, mask)\n",
    "                hausdorff_distances.append(hausdorff)\n",
    "\n",
    "                avg_surf_dist = average_surface_distance(pred, mask)\n",
    "                avg_surface_distances.append(avg_surf_dist)\n",
    "\n",
    "            times.append(end_time - start_time)\n",
    "\n",
    "    # Média das métricas\n",
    "    avg_dice = np.mean(dice_scores)\n",
    "    avg_jaccard = np.mean(jaccard_scores)\n",
    "    avg_hausdorff = np.mean(hausdorff_distances)\n",
    "    avg_asd = np.mean(avg_surface_distances)\n",
    "    total_time = np.mean(times)\n",
    "    \n",
    "    return {\n",
    "        \"Mean Dice Coefficient\": avg_dice,\n",
    "        \"Mean Jaccard Index\": avg_jaccard,\n",
    "        \"Mean Hausdorff Distance\": avg_hausdorff,\n",
    "        \"Mean Average Surface Distance\": avg_asd,\n",
    "        \"Processing Time (s)\": total_time\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: Densenet201 / Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 / Loss: 0.4383\n",
      "Epoch 2/30 / Loss: 0.2937\n",
      "Epoch 3/30 / Loss: 0.2255\n",
      "Epoch 4/30 / Loss: 0.1724\n",
      "Epoch 5/30 / Loss: 0.1361\n",
      "Epoch 6/30 / Loss: 0.1101\n",
      "Epoch 7/30 / Loss: 0.0905\n",
      "Epoch 8/30 / Loss: 0.0788\n",
      "Epoch 9/30 / Loss: 0.0663\n",
      "Epoch 10/30 / Loss: 0.0582\n",
      "Epoch 11/30 / Loss: 0.0501\n",
      "Epoch 12/30 / Loss: 0.0454\n",
      "Epoch 13/30 / Loss: 0.0409\n",
      "Epoch 14/30 / Loss: 0.0369\n",
      "Epoch 15/30 / Loss: 0.0331\n",
      "Epoch 16/30 / Loss: 0.0306\n",
      "Epoch 17/30 / Loss: 0.0281\n",
      "Epoch 18/30 / Loss: 0.0265\n",
      "Epoch 19/30 / Loss: 0.0246\n",
      "Epoch 20/30 / Loss: 0.0234\n",
      "Epoch 21/30 / Loss: 0.0223\n",
      "Epoch 22/30 / Loss: 0.0209\n",
      "Epoch 23/30 / Loss: 0.0196\n",
      "Epoch 24/30 / Loss: 0.0187\n",
      "Epoch 25/30 / Loss: 0.0179\n",
      "Epoch 26/30 / Loss: 0.0170\n",
      "Epoch 27/30 / Loss: 0.0160\n",
      "Epoch 28/30 / Loss: 0.0154\n",
      "Epoch 29/30 / Loss: 0.0146\n",
      "Epoch 30/30 / Loss: 0.0146\n",
      "Modelo treinado!\n",
      "\n",
      "Métricas de avaliação:\n",
      "\tMean Dice Coefficient: 0.9815\n",
      "\tMean Jaccard Index: 0.9640\n",
      "\tMean Hausdorff Distance: 7.0597\n",
      "\tMean Average Surface Distance: 0.0538\n",
      "\tProcessing Time (s): 0.4064\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = get_preprocessing_fn('densenet201', pretrained='imagenet')\n",
    "\n",
    "densenet201_unet_model = smp.Unet(\n",
    "    encoder_name=\"densenet201\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(densenet201_unet_model.parameters(), lr=1e-4)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, \"densenet201_unet_model.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    densenet201_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado!\")\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    "    )\n",
    "\n",
    "    train(densenet201_unet_model, train_loader, loss_fn, optimizer, N_EPOCHS)\n",
    "    save_model(densenet201_unet_model, model_path)\n",
    "    print(\"Modelo treinado!\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "metrics = evaluate(densenet201_unet_model, test_loader)\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"\\t{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: Resnet152 / Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_770/3369070554.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet152_unet_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado!\n",
      "\n",
      "Métricas de avaliação:\n",
      "\tMean Dice Coefficient: 0.9830\n",
      "\tMean Jaccard Index: 0.9669\n",
      "\tMean Hausdorff Distance: 5.6518\n",
      "\tMean Average Surface Distance: 0.0348\n",
      "\tProcessing Time (s): 0.0251\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = get_preprocessing_fn(\"resnet152\", pretrained=\"imagenet\")\n",
    "\n",
    "resnet152_unet_model = smp.Unet(\n",
    "    encoder_name=\"resnet152\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(resnet152_unet_model.parameters(), lr=1e-4)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, \"resnet152_unet_model.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    resnet152_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado!\")\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    "    )\n",
    "\n",
    "    train(resnet152_unet_model, train_loader, loss_fn, optimizer, N_EPOCHS)\n",
    "    save_model(resnet152_unet_model, model_path)\n",
    "    print(\"Modelo treinado!\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "metrics = evaluate(resnet152_unet_model, test_loader)\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"\\t{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: MobileNetV2 / Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_770/2516534121.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mobilenet_v2_unet_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas de avaliação:\n",
      "\tMean Dice Coefficient: 0.9764\n",
      "\tMean Jaccard Index: 0.9542\n",
      "\tMean Hausdorff Distance: 10.2416\n",
      "\tMean Average Surface Distance: 0.1046\n",
      "\tProcessing Time (s): 0.0067\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = get_preprocessing_fn(\"mobilenet_v2\", pretrained=\"imagenet\")\n",
    "\n",
    "mobilenet_v2_unet_model = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(mobilenet_v2_unet_model.parameters(), lr=1e-4)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, \"mobilenet_v2_unet_model.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    mobilenet_v2_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado!\")\n",
    "else:\n",
    "    print(\"Treinando modelo...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    "    )\n",
    "\n",
    "    train(mobilenet_v2_unet_model, train_loader, loss_fn, optimizer, N_EPOCHS)\n",
    "    save_model(mobilenet_v2_unet_model, model_path)\n",
    "    print(\"Modelo treinado!\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "metrics = evaluate(mobilenet_v2_unet_model, test_loader)\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"\\t{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: Xception / Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth\" to /home/davi/.cache/torch/hub/checkpoints/xception-43020ad28.pth\n",
      "100%|██████████| 87.4M/87.4M [04:17<00:00, 356kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo...\n",
      "Epoch 1/30 / Loss: 0.4070\n",
      "Epoch 2/30 / Loss: 0.2316\n",
      "Epoch 3/30 / Loss: 0.1620\n",
      "Epoch 4/30 / Loss: 0.1225\n",
      "Epoch 5/30 / Loss: 0.0986\n",
      "Epoch 6/30 / Loss: 0.0803\n",
      "Epoch 7/30 / Loss: 0.0676\n",
      "Epoch 8/30 / Loss: 0.0576\n",
      "Epoch 9/30 / Loss: 0.0505\n",
      "Epoch 10/30 / Loss: 0.0445\n",
      "Epoch 11/30 / Loss: 0.0401\n",
      "Epoch 12/30 / Loss: 0.0361\n",
      "Epoch 13/30 / Loss: 0.0329\n",
      "Epoch 14/30 / Loss: 0.0299\n",
      "Epoch 15/30 / Loss: 0.0280\n",
      "Epoch 16/30 / Loss: 0.0257\n",
      "Epoch 17/30 / Loss: 0.0238\n",
      "Epoch 18/30 / Loss: 0.0232\n",
      "Epoch 19/30 / Loss: 0.0221\n",
      "Epoch 20/30 / Loss: 0.0209\n",
      "Epoch 21/30 / Loss: 0.0191\n",
      "Epoch 22/30 / Loss: 0.0187\n",
      "Epoch 23/30 / Loss: 0.0181\n",
      "Epoch 24/30 / Loss: 0.0170\n",
      "Epoch 25/30 / Loss: 0.0158\n",
      "Epoch 26/30 / Loss: 0.0152\n",
      "Epoch 27/30 / Loss: 0.0149\n",
      "Epoch 28/30 / Loss: 0.0143\n",
      "Epoch 29/30 / Loss: 0.0137\n",
      "Epoch 30/30 / Loss: 0.0132\n",
      "Modelo treinado!\n",
      "\n",
      "Métricas de avaliação:\n",
      "\tMean Dice Coefficient: 0.9794\n",
      "\tMean Jaccard Index: 0.9601\n",
      "\tMean Hausdorff Distance: 8.9616\n",
      "\tMean Average Surface Distance: 0.0950\n",
      "\tProcessing Time (s): 0.0086\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = get_preprocessing_fn(\"xception\", pretrained=\"imagenet\")\n",
    "\n",
    "xception_unet_model = smp.Unet(\n",
    "    encoder_name=\"xception\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(xception_unet_model.parameters(), lr=1e-4)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, \"xception_unet_model.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    xception_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado!\")\n",
    "else:\n",
    "    print(\"Treinando modelo...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    "    )\n",
    "\n",
    "    train(xception_unet_model, train_loader, loss_fn, optimizer, N_EPOCHS)\n",
    "    save_model(xception_unet_model, model_path)\n",
    "    print(\"Modelo treinado!\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "metrics = evaluate(xception_unet_model, test_loader)\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"\\t{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: VGG19 / Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /home/davi/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:11<00:00, 51.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo...\n",
      "Epoch 1/30 / Loss: 0.4269\n",
      "Epoch 2/30 / Loss: 0.2784\n",
      "Epoch 3/30 / Loss: 0.2206\n",
      "Epoch 4/30 / Loss: 0.1808\n",
      "Epoch 5/30 / Loss: 0.1519\n",
      "Epoch 6/30 / Loss: 0.1290\n",
      "Epoch 7/30 / Loss: 0.1107\n",
      "Epoch 8/30 / Loss: 0.0950\n",
      "Epoch 9/30 / Loss: 0.0832\n",
      "Epoch 10/30 / Loss: 0.0736\n",
      "Epoch 11/30 / Loss: 0.0651\n",
      "Epoch 12/30 / Loss: 0.0586\n",
      "Epoch 13/30 / Loss: 0.0524\n",
      "Epoch 14/30 / Loss: 0.0472\n",
      "Epoch 15/30 / Loss: 0.0426\n",
      "Epoch 16/30 / Loss: 0.0394\n",
      "Epoch 17/30 / Loss: 0.0361\n",
      "Epoch 18/30 / Loss: 0.0336\n",
      "Epoch 19/30 / Loss: 0.0321\n",
      "Epoch 20/30 / Loss: 0.0287\n",
      "Epoch 21/30 / Loss: 0.0275\n",
      "Epoch 22/30 / Loss: 0.0256\n",
      "Epoch 23/30 / Loss: 0.0236\n",
      "Epoch 24/30 / Loss: 0.0224\n",
      "Epoch 25/30 / Loss: 0.0212\n",
      "Epoch 26/30 / Loss: 0.0197\n",
      "Epoch 27/30 / Loss: 0.0186\n",
      "Epoch 28/30 / Loss: 0.0180\n",
      "Epoch 29/30 / Loss: 0.0170\n",
      "Epoch 30/30 / Loss: 0.0160\n",
      "Modelo treinado!\n",
      "\n",
      "Métricas de avaliação:\n",
      "\tMean Dice Coefficient: 0.9840\n",
      "\tMean Jaccard Index: 0.9688\n",
      "\tMean Hausdorff Distance: 6.9957\n",
      "\tMean Average Surface Distance: 0.0483\n",
      "\tProcessing Time (s): 0.0098\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = get_preprocessing_fn(\"vgg19\", pretrained=\"imagenet\")\n",
    "\n",
    "vgg19_unet_model = smp.Unet(\n",
    "    encoder_name=\"vgg19\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(vgg19_unet_model.parameters(), lr=1e-4)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, \"vgg19_unet_model.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    vgg19_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado!\")\n",
    "else:\n",
    "    print(\"Treinando modelo...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    "    )\n",
    "\n",
    "    train(vgg19_unet_model, train_loader, loss_fn, optimizer, N_EPOCHS)\n",
    "    save_model(vgg19_unet_model, model_path)\n",
    "    print(\"Modelo treinado!\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "metrics = evaluate(vgg19_unet_model, test_loader)\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"\\t{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: InceptionV4 / Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/inceptionv4-8e4777a0.pth\" to /home/davi/.cache/torch/hub/checkpoints/inceptionv4-8e4777a0.pth\n",
      "100%|██████████| 163M/163M [08:00<00:00, 356kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo...\n",
      "Epoch 1/30 / Loss: 0.3883\n",
      "Epoch 2/30 / Loss: 0.1879\n",
      "Epoch 3/30 / Loss: 0.1314\n",
      "Epoch 4/30 / Loss: 0.1019\n",
      "Epoch 5/30 / Loss: 0.0839\n",
      "Epoch 6/30 / Loss: 0.0696\n",
      "Epoch 7/30 / Loss: 0.0596\n",
      "Epoch 8/30 / Loss: 0.0518\n",
      "Epoch 9/30 / Loss: 0.0452\n",
      "Epoch 10/30 / Loss: 0.0404\n",
      "Epoch 11/30 / Loss: 0.0361\n",
      "Epoch 12/30 / Loss: 0.0328\n",
      "Epoch 13/30 / Loss: 0.0305\n",
      "Epoch 14/30 / Loss: 0.0279\n",
      "Epoch 15/30 / Loss: 0.0254\n",
      "Epoch 16/30 / Loss: 0.0237\n",
      "Epoch 17/30 / Loss: 0.0226\n",
      "Epoch 18/30 / Loss: 0.0211\n",
      "Epoch 19/30 / Loss: 0.0199\n",
      "Epoch 20/30 / Loss: 0.0191\n",
      "Epoch 21/30 / Loss: 0.0177\n",
      "Epoch 22/30 / Loss: 0.0169\n",
      "Epoch 23/30 / Loss: 0.0175\n",
      "Epoch 24/30 / Loss: 0.0161\n",
      "Epoch 25/30 / Loss: 0.0151\n",
      "Epoch 26/30 / Loss: 0.0145\n",
      "Epoch 27/30 / Loss: 0.0136\n",
      "Epoch 28/30 / Loss: 0.0133\n",
      "Epoch 29/30 / Loss: 0.0124\n",
      "Epoch 30/30 / Loss: 0.0117\n",
      "Modelo treinado!\n",
      "\n",
      "Métricas de avaliação:\n",
      "\tMean Dice Coefficient: 0.9812\n",
      "\tMean Jaccard Index: 0.9634\n",
      "\tMean Hausdorff Distance: 7.7922\n",
      "\tMean Average Surface Distance: 0.0748\n",
      "\tProcessing Time (s): 0.0224\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = get_preprocessing_fn(\"inceptionv4\", pretrained=\"imagenet+background\")\n",
    "\n",
    "inceptionv4_unet_model = smp.Unet(\n",
    "    encoder_name=\"inceptionv4\",\n",
    "    encoder_weights=\"imagenet+background\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(inceptionv4_unet_model.parameters(), lr=1e-4)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, \"inceptionv4_unet_model.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    inceptionv4_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado!\")\n",
    "else:\n",
    "    print(\"Treinando modelo...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    "    )\n",
    "\n",
    "    train(inceptionv4_unet_model, train_loader, loss_fn, optimizer, N_EPOCHS)\n",
    "    save_model(inceptionv4_unet_model, model_path)\n",
    "    print(\"Modelo treinado!\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "metrics = evaluate(inceptionv4_unet_model, test_loader)\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"\\t{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
